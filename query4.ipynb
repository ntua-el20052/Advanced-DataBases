{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de4ce5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>21</td><td>application_1738075734771_0022</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-12.eu-central-1.compute.internal:20888/proxy/application_1738075734771_0022/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-72.eu-central-1.compute.internal:8042/node/containerlogs/container_1738075734771_0022_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-Income Areas:\n",
      "+--------------------+---+\n",
      "|      Victim Descent|  #|\n",
      "+--------------------+---+\n",
      "|               White|580|\n",
      "|               Other| 85|\n",
      "|Hispanic/Latin/Me...| 60|\n",
      "|             Unknown| 51|\n",
      "|               Black| 38|\n",
      "|         Other Asian| 19|\n",
      "|             Chinese|  1|\n",
      "|American Indian/A...|  1|\n",
      "+--------------------+---+\n",
      "\n",
      "Low-Income Areas:\n",
      "+--------------------+----+\n",
      "|      Victim Descent|   #|\n",
      "+--------------------+----+\n",
      "|Hispanic/Latin/Me...|3941|\n",
      "|               Black|1170|\n",
      "|               White| 367|\n",
      "|               Other| 325|\n",
      "|         Other Asian|  45|\n",
      "|             Unknown|  14|\n",
      "|              Korean|   6|\n",
      "|American Indian/A...|   2|\n",
      "|            Filipino|   1|\n",
      "|           Guamanian|   1|\n",
      "|    Pacific Islander|   1|\n",
      "+--------------------+----+\n",
      "\n",
      "Time taken: 70.19 seconds"
     ]
    }
   ],
   "source": [
    "from sedona.spark import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, sum, count, desc, regexp_replace, expr\n",
    "import time\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Query 4 - Racial Profile Analysis\") \\\n",
    "    .config(\"spark.executor.instances\", \"2\") \\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .config(\"spark.executor.cores\", \"1\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Create Sedona context\n",
    "sedona = SedonaContext.create(spark)\n",
    "SedonaRegistrator.registerAll(spark)\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Load GeoJSON data for Census Blocks\n",
    "geojson_path = \"s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson\"\n",
    "blocks_df = spark.read.format(\"geojson\") \\\n",
    "            .option(\"multiLine\", \"true\").load(geojson_path) \\\n",
    "            .selectExpr(\"explode(features) as features\") \\\n",
    "            .select(\"features.*\")\n",
    "\n",
    "# Formatting magic\n",
    "flattened_df = blocks_df.select(\n",
    "                [col(f\"properties.{col_name}\").alias(col_name) for col_name in \n",
    "                blocks_df.schema[\"properties\"].dataType.fieldNames()] + [\"geometry\"]) \\\n",
    "            .drop(\"properties\") \\\n",
    "            .drop(\"type\")\n",
    "\n",
    "# Load datasets\n",
    "crime_data = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv\", header=True, inferSchema=True)\n",
    "income_data = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv\", header=True, inferSchema=True)\n",
    "race_codes = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/RE_codes.csv\", header=True, inferSchema=True) \\\n",
    "            .withColumnRenamed(\"Vict Descent\", \"Race_Code\") \\\n",
    "            .withColumnRenamed(\"Vict Descent Full\", \"Race_Description\")\n",
    "\n",
    "# Load population data from GeoJSON\n",
    "population_df = blocks_df.select(\n",
    "    col(\"properties.ZCTA10\").cast(\"string\").alias(\"Zip Code\"),\n",
    "    col(\"properties.POP_2010\").cast(\"float\").alias(\"population\"),\n",
    "    col(\"properties.HOUSING10\").cast(\"float\").alias(\"households\")\n",
    ")\n",
    "\n",
    "# Aggregate population and household data by ZIP code\n",
    "population_aggregated_df = population_df.groupBy(\"Zip Code\").agg(\n",
    "    sum(\"population\").alias(\"total_population\"),\n",
    "    sum(\"households\").alias(\"total_households\")\n",
    ")\n",
    "\n",
    "# Process income data\n",
    "income_data = income_data.select(\n",
    "    col(\"Zip Code\").cast(\"string\"),\n",
    "    regexp_replace(col(\"Estimated Median Income\"), r'[\\$,]', '').cast(\"float\").alias(\"household_income\")\n",
    ")\n",
    "\n",
    "# Join population and income data by ZIP code\n",
    "joined_df = population_aggregated_df.join(income_data, \"Zip Code\", \"inner\")\n",
    "\n",
    "# Compute per capita income\n",
    "joined_df = joined_df.withColumn(\n",
    "    \"per_capita_income\", (col(\"total_households\") * col(\"household_income\")) / col(\"total_population\")\n",
    ")\n",
    "\n",
    "# Identify the 3 ZIP codes with highest and lowest per capita income\n",
    "high_income_zips = joined_df.orderBy(desc(\"per_capita_income\")).limit(3)\n",
    "low_income_zips = joined_df.orderBy(\"per_capita_income\").limit(3)\n",
    "\n",
    "# Broadcast high-income and low-income ZIP codes\n",
    "high_income_zip_list = [row[\"Zip Code\"] for row in high_income_zips.collect()]\n",
    "low_income_zip_list = [row[\"Zip Code\"] for row in low_income_zips.collect()]\n",
    "\n",
    "# Filter census blocks for high- and low-income areas\n",
    "high_income_blocks = flattened_df.filter(flattened_df[\"ZCTA10\"].isin(high_income_zip_list))\n",
    "low_income_blocks = flattened_df.filter(flattened_df[\"ZCTA10\"].isin(low_income_zip_list))\n",
    "\n",
    "# Filter crime data for 2015\n",
    "crime_2015 = crime_data.filter(col(\"DATE OCC\").contains(\"2015\"))\n",
    "\n",
    "# Remove invalid records (Null Island)\n",
    "crime_2015 = crime_2015.filter((col(\"LAT\").isNotNull()) & (col(\"LON\").isNotNull()) & (col(\"LAT\") != 0) & (col(\"LON\") != 0))\n",
    "\n",
    "# Add geometry column to crime data\n",
    "crime_2015 = crime_2015.withColumn(\"geometry\", ST_Point(col(\"LON\"), col(\"LAT\")))\n",
    "\n",
    "# Join crime data with high- and low-income census blocks using spatial join\n",
    "high_income_crimes = crime_2015.join(\n",
    "    high_income_blocks,\n",
    "    ST_Within(crime_2015.geometry, high_income_blocks.geometry),\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "low_income_crimes = crime_2015.join(\n",
    "    low_income_blocks,\n",
    "    ST_Within(crime_2015.geometry, low_income_blocks.geometry),\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "# Map racial profile codes to full descriptions\n",
    "high_income_racial_profile = high_income_crimes \\\n",
    "    .join(race_codes, high_income_crimes[\"Vict Descent\"] == race_codes[\"Race_Code\"], \"left\") \\\n",
    "    .filter(col(\"Race_Description\").isNotNull()) \\\n",
    "    .groupBy(\"Race_Description\") \\\n",
    "    .agg(count(\"Vict Descent\").alias(\"Victim_Count\")) \\\n",
    "    .orderBy(desc(\"Victim_Count\")) \\\n",
    "    .withColumnRenamed(\"Race_Description\", \"Victim Descent\") \\\n",
    "    .withColumnRenamed(\"Victim_Count\", \"#\")\n",
    "\n",
    "low_income_racial_profile = low_income_crimes \\\n",
    "    .join(race_codes, low_income_crimes[\"Vict Descent\"] == race_codes[\"Race_Code\"], \"left\") \\\n",
    "    .filter(col(\"Race_Description\").isNotNull()) \\\n",
    "    .groupBy(\"Race_Description\") \\\n",
    "    .agg(count(\"Vict Descent\").alias(\"Victim_Count\")) \\\n",
    "    .orderBy(desc(\"Victim_Count\")) \\\n",
    "    .withColumnRenamed(\"Race_Description\", \"Victim Descent\") \\\n",
    "    .withColumnRenamed(\"Victim_Count\", \"#\")\n",
    "\n",
    "# Show results\n",
    "print(\"High-Income Areas:\")\n",
    "high_income_racial_profile.show()\n",
    "\n",
    "print(\"Low-Income Areas:\")\n",
    "low_income_racial_profile.show()\n",
    "\n",
    "# Stop timing and print out the execution duration\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken: {elapsed_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "690262a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-Income Areas:\n",
      "+--------------------+---+\n",
      "|      Victim Descent|  #|\n",
      "+--------------------+---+\n",
      "|               White|580|\n",
      "|               Other| 85|\n",
      "|Hispanic/Latin/Me...| 60|\n",
      "|             Unknown| 51|\n",
      "|               Black| 38|\n",
      "|         Other Asian| 19|\n",
      "|             Chinese|  1|\n",
      "|American Indian/A...|  1|\n",
      "+--------------------+---+\n",
      "\n",
      "Low-Income Areas:\n",
      "+--------------------+----+\n",
      "|      Victim Descent|   #|\n",
      "+--------------------+----+\n",
      "|Hispanic/Latin/Me...|3941|\n",
      "|               Black|1170|\n",
      "|               White| 367|\n",
      "|               Other| 325|\n",
      "|         Other Asian|  45|\n",
      "|             Unknown|  14|\n",
      "|              Korean|   6|\n",
      "|American Indian/A...|   2|\n",
      "|    Pacific Islander|   1|\n",
      "|            Filipino|   1|\n",
      "|           Guamanian|   1|\n",
      "+--------------------+----+\n",
      "\n",
      "Time taken: 54.35 seconds"
     ]
    }
   ],
   "source": [
    "from sedona.spark import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, sum, count, desc, regexp_replace, expr\n",
    "import time\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Query 4 - Racial Profile Analysis\") \\\n",
    "    .config(\"spark.executor.instances\", \"2\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.cores\", \"2\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Create Sedona context\n",
    "sedona = SedonaContext.create(spark)\n",
    "SedonaRegistrator.registerAll(spark)\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Load GeoJSON data for Census Blocks\n",
    "geojson_path = \"s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson\"\n",
    "blocks_df = spark.read.format(\"geojson\") \\\n",
    "            .option(\"multiLine\", \"true\").load(geojson_path) \\\n",
    "            .selectExpr(\"explode(features) as features\") \\\n",
    "            .select(\"features.*\")\n",
    "\n",
    "# Formatting magic\n",
    "flattened_df = blocks_df.select(\n",
    "                [col(f\"properties.{col_name}\").alias(col_name) for col_name in \n",
    "                blocks_df.schema[\"properties\"].dataType.fieldNames()] + [\"geometry\"]) \\\n",
    "            .drop(\"properties\") \\\n",
    "            .drop(\"type\")\n",
    "\n",
    "# Load datasets\n",
    "crime_data = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv\", header=True, inferSchema=True)\n",
    "income_data = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv\", header=True, inferSchema=True)\n",
    "race_codes = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/RE_codes.csv\", header=True, inferSchema=True) \\\n",
    "            .withColumnRenamed(\"Vict Descent\", \"Race_Code\") \\\n",
    "            .withColumnRenamed(\"Vict Descent Full\", \"Race_Description\")\n",
    "\n",
    "# Load population data from GeoJSON\n",
    "population_df = blocks_df.select(\n",
    "    col(\"properties.ZCTA10\").cast(\"string\").alias(\"Zip Code\"),\n",
    "    col(\"properties.POP_2010\").cast(\"float\").alias(\"population\"),\n",
    "    col(\"properties.HOUSING10\").cast(\"float\").alias(\"households\")\n",
    ")\n",
    "\n",
    "# Aggregate population and household data by ZIP code\n",
    "population_aggregated_df = population_df.groupBy(\"Zip Code\").agg(\n",
    "    sum(\"population\").alias(\"total_population\"),\n",
    "    sum(\"households\").alias(\"total_households\")\n",
    ")\n",
    "\n",
    "# Process income data\n",
    "income_data = income_data.select(\n",
    "    col(\"Zip Code\").cast(\"string\"),\n",
    "    regexp_replace(col(\"Estimated Median Income\"), r'[\\$,]', '').cast(\"float\").alias(\"household_income\")\n",
    ")\n",
    "\n",
    "# Join population and income data by ZIP code\n",
    "joined_df = population_aggregated_df.join(income_data, \"Zip Code\", \"inner\")\n",
    "\n",
    "# Compute per capita income\n",
    "joined_df = joined_df.withColumn(\n",
    "    \"per_capita_income\", (col(\"total_households\") * col(\"household_income\")) / col(\"total_population\")\n",
    ")\n",
    "\n",
    "# Identify the 3 ZIP codes with highest and lowest per capita income\n",
    "high_income_zips = joined_df.orderBy(desc(\"per_capita_income\")).limit(3)\n",
    "low_income_zips = joined_df.orderBy(\"per_capita_income\").limit(3)\n",
    "\n",
    "# Broadcast high-income and low-income ZIP codes\n",
    "high_income_zip_list = [row[\"Zip Code\"] for row in high_income_zips.collect()]\n",
    "low_income_zip_list = [row[\"Zip Code\"] for row in low_income_zips.collect()]\n",
    "\n",
    "# Filter census blocks for high- and low-income areas\n",
    "high_income_blocks = flattened_df.filter(flattened_df[\"ZCTA10\"].isin(high_income_zip_list))\n",
    "low_income_blocks = flattened_df.filter(flattened_df[\"ZCTA10\"].isin(low_income_zip_list))\n",
    "\n",
    "# Filter crime data for 2015\n",
    "crime_2015 = crime_data.filter(col(\"DATE OCC\").contains(\"2015\"))\n",
    "\n",
    "# Remove invalid records (Null Island)\n",
    "crime_2015 = crime_2015.filter((col(\"LAT\").isNotNull()) & (col(\"LON\").isNotNull()) & (col(\"LAT\") != 0) & (col(\"LON\") != 0))\n",
    "\n",
    "# Add geometry column to crime data\n",
    "crime_2015 = crime_2015.withColumn(\"geometry\", ST_Point(col(\"LON\"), col(\"LAT\")))\n",
    "\n",
    "# Join crime data with high- and low-income census blocks using spatial join\n",
    "high_income_crimes = crime_2015.join(\n",
    "    high_income_blocks,\n",
    "    ST_Within(crime_2015.geometry, high_income_blocks.geometry),\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "low_income_crimes = crime_2015.join(\n",
    "    low_income_blocks,\n",
    "    ST_Within(crime_2015.geometry, low_income_blocks.geometry),\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "# Map racial profile codes to full descriptions\n",
    "high_income_racial_profile = high_income_crimes \\\n",
    "    .join(race_codes, high_income_crimes[\"Vict Descent\"] == race_codes[\"Race_Code\"], \"left\") \\\n",
    "    .filter(col(\"Race_Description\").isNotNull()) \\\n",
    "    .groupBy(\"Race_Description\") \\\n",
    "    .agg(count(\"Vict Descent\").alias(\"Victim_Count\")) \\\n",
    "    .orderBy(desc(\"Victim_Count\")) \\\n",
    "    .withColumnRenamed(\"Race_Description\", \"Victim Descent\") \\\n",
    "    .withColumnRenamed(\"Victim_Count\", \"#\")\n",
    "\n",
    "low_income_racial_profile = low_income_crimes \\\n",
    "    .join(race_codes, low_income_crimes[\"Vict Descent\"] == race_codes[\"Race_Code\"], \"left\") \\\n",
    "    .filter(col(\"Race_Description\").isNotNull()) \\\n",
    "    .groupBy(\"Race_Description\") \\\n",
    "    .agg(count(\"Vict Descent\").alias(\"Victim_Count\")) \\\n",
    "    .orderBy(desc(\"Victim_Count\")) \\\n",
    "    .withColumnRenamed(\"Race_Description\", \"Victim Descent\") \\\n",
    "    .withColumnRenamed(\"Victim_Count\", \"#\")\n",
    "\n",
    "# Show results\n",
    "print(\"High-Income Areas:\")\n",
    "high_income_racial_profile.show()\n",
    "\n",
    "print(\"Low-Income Areas:\")\n",
    "low_income_racial_profile.show()\n",
    "\n",
    "# Stop timing and print out the execution duration\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken: {elapsed_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdffb1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-Income Areas:\n",
      "+--------------------+---+\n",
      "|      Victim Descent|  #|\n",
      "+--------------------+---+\n",
      "|               White|580|\n",
      "|               Other| 85|\n",
      "|Hispanic/Latin/Me...| 60|\n",
      "|             Unknown| 51|\n",
      "|               Black| 38|\n",
      "|         Other Asian| 19|\n",
      "|             Chinese|  1|\n",
      "|American Indian/A...|  1|\n",
      "+--------------------+---+\n",
      "\n",
      "Low-Income Areas:\n",
      "+--------------------+----+\n",
      "|      Victim Descent|   #|\n",
      "+--------------------+----+\n",
      "|Hispanic/Latin/Me...|3941|\n",
      "|               Black|1170|\n",
      "|               White| 367|\n",
      "|               Other| 325|\n",
      "|         Other Asian|  45|\n",
      "|             Unknown|  14|\n",
      "|              Korean|   6|\n",
      "|American Indian/A...|   2|\n",
      "|    Pacific Islander|   1|\n",
      "|            Filipino|   1|\n",
      "|           Guamanian|   1|\n",
      "+--------------------+----+\n",
      "\n",
      "Time taken: 49.37 seconds"
     ]
    }
   ],
   "source": [
    "from sedona.spark import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, sum, count, desc, regexp_replace, expr\n",
    "import time\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Query 4 - Racial Profile Analysis\") \\\n",
    "    .config(\"spark.executor.instances\", \"2\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.cores\", \"4\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Create Sedona context\n",
    "sedona = SedonaContext.create(spark)\n",
    "SedonaRegistrator.registerAll(spark)\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Load GeoJSON data for Census Blocks\n",
    "geojson_path = \"s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson\"\n",
    "blocks_df = spark.read.format(\"geojson\") \\\n",
    "            .option(\"multiLine\", \"true\").load(geojson_path) \\\n",
    "            .selectExpr(\"explode(features) as features\") \\\n",
    "            .select(\"features.*\")\n",
    "\n",
    "# Formatting magic\n",
    "flattened_df = blocks_df.select(\n",
    "                [col(f\"properties.{col_name}\").alias(col_name) for col_name in \n",
    "                blocks_df.schema[\"properties\"].dataType.fieldNames()] + [\"geometry\"]) \\\n",
    "            .drop(\"properties\") \\\n",
    "            .drop(\"type\")\n",
    "\n",
    "# Load datasets\n",
    "crime_data = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv\", header=True, inferSchema=True)\n",
    "income_data = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv\", header=True, inferSchema=True)\n",
    "race_codes = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/RE_codes.csv\", header=True, inferSchema=True) \\\n",
    "            .withColumnRenamed(\"Vict Descent\", \"Race_Code\") \\\n",
    "            .withColumnRenamed(\"Vict Descent Full\", \"Race_Description\")\n",
    "\n",
    "# Load population data from GeoJSON\n",
    "population_df = blocks_df.select(\n",
    "    col(\"properties.ZCTA10\").cast(\"string\").alias(\"Zip Code\"),\n",
    "    col(\"properties.POP_2010\").cast(\"float\").alias(\"population\"),\n",
    "    col(\"properties.HOUSING10\").cast(\"float\").alias(\"households\")\n",
    ")\n",
    "\n",
    "# Aggregate population and household data by ZIP code\n",
    "population_aggregated_df = population_df.groupBy(\"Zip Code\").agg(\n",
    "    sum(\"population\").alias(\"total_population\"),\n",
    "    sum(\"households\").alias(\"total_households\")\n",
    ")\n",
    "\n",
    "# Process income data\n",
    "income_data = income_data.select(\n",
    "    col(\"Zip Code\").cast(\"string\"),\n",
    "    regexp_replace(col(\"Estimated Median Income\"), r'[\\$,]', '').cast(\"float\").alias(\"household_income\")\n",
    ")\n",
    "\n",
    "# Join population and income data by ZIP code\n",
    "joined_df = population_aggregated_df.join(income_data, \"Zip Code\", \"inner\")\n",
    "\n",
    "# Compute per capita income\n",
    "joined_df = joined_df.withColumn(\n",
    "    \"per_capita_income\", (col(\"total_households\") * col(\"household_income\")) / col(\"total_population\")\n",
    ")\n",
    "\n",
    "# Identify the 3 ZIP codes with highest and lowest per capita income\n",
    "high_income_zips = joined_df.orderBy(desc(\"per_capita_income\")).limit(3)\n",
    "low_income_zips = joined_df.orderBy(\"per_capita_income\").limit(3)\n",
    "\n",
    "# Broadcast high-income and low-income ZIP codes\n",
    "high_income_zip_list = [row[\"Zip Code\"] for row in high_income_zips.collect()]\n",
    "low_income_zip_list = [row[\"Zip Code\"] for row in low_income_zips.collect()]\n",
    "\n",
    "# Filter census blocks for high- and low-income areas\n",
    "high_income_blocks = flattened_df.filter(flattened_df[\"ZCTA10\"].isin(high_income_zip_list))\n",
    "low_income_blocks = flattened_df.filter(flattened_df[\"ZCTA10\"].isin(low_income_zip_list))\n",
    "\n",
    "# Filter crime data for 2015\n",
    "crime_2015 = crime_data.filter(col(\"DATE OCC\").contains(\"2015\"))\n",
    "\n",
    "# Remove invalid records (Null Island)\n",
    "crime_2015 = crime_2015.filter((col(\"LAT\").isNotNull()) & (col(\"LON\").isNotNull()) & (col(\"LAT\") != 0) & (col(\"LON\") != 0))\n",
    "\n",
    "# Add geometry column to crime data\n",
    "crime_2015 = crime_2015.withColumn(\"geometry\", ST_Point(col(\"LON\"), col(\"LAT\")))\n",
    "\n",
    "# Join crime data with high- and low-income census blocks using spatial join\n",
    "high_income_crimes = crime_2015.join(\n",
    "    high_income_blocks,\n",
    "    ST_Within(crime_2015.geometry, high_income_blocks.geometry),\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "low_income_crimes = crime_2015.join(\n",
    "    low_income_blocks,\n",
    "    ST_Within(crime_2015.geometry, low_income_blocks.geometry),\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "# Map racial profile codes to full descriptions\n",
    "high_income_racial_profile = high_income_crimes \\\n",
    "    .join(race_codes, high_income_crimes[\"Vict Descent\"] == race_codes[\"Race_Code\"], \"left\") \\\n",
    "    .filter(col(\"Race_Description\").isNotNull()) \\\n",
    "    .groupBy(\"Race_Description\") \\\n",
    "    .agg(count(\"Vict Descent\").alias(\"Victim_Count\")) \\\n",
    "    .orderBy(desc(\"Victim_Count\")) \\\n",
    "    .withColumnRenamed(\"Race_Description\", \"Victim Descent\") \\\n",
    "    .withColumnRenamed(\"Victim_Count\", \"#\")\n",
    "\n",
    "low_income_racial_profile = low_income_crimes \\\n",
    "    .join(race_codes, low_income_crimes[\"Vict Descent\"] == race_codes[\"Race_Code\"], \"left\") \\\n",
    "    .filter(col(\"Race_Description\").isNotNull()) \\\n",
    "    .groupBy(\"Race_Description\") \\\n",
    "    .agg(count(\"Vict Descent\").alias(\"Victim_Count\")) \\\n",
    "    .orderBy(desc(\"Victim_Count\")) \\\n",
    "    .withColumnRenamed(\"Race_Description\", \"Victim Descent\") \\\n",
    "    .withColumnRenamed(\"Victim_Count\", \"#\")\n",
    "\n",
    "# Show results\n",
    "print(\"High-Income Areas:\")\n",
    "high_income_racial_profile.show()\n",
    "\n",
    "print(\"Low-Income Areas:\")\n",
    "low_income_racial_profile.show()\n",
    "\n",
    "# Stop timing and print out the execution duration\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken: {elapsed_time:.2f} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
